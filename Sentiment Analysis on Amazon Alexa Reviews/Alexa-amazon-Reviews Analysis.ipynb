{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Import Libraries\n",
    "\n",
    "Start by importing the necessary libraries for data manipulation, visualization, natural language processing and machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import re\n",
    "import nltk\n",
    "from wordcloud import WordCloud\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Load and Explore Data\n",
    "\n",
    "Load your dataset containing house features and prices using Pandas and explore it through Exploratory Data Analysis (EDA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "df = pd.read_csv('amazon_alexa.tsv', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the First few Rows of Dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Missing Values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Information about the Dataset, Missing Values and Datatypes\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Data Preprocessing and Feature Engineering\n",
    "\n",
    "Based on the insights from EDA, perform data preprocessing and feature engineering to prepare the data for Random Forest Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value counts of variation \n",
    "variation_label = df.variation.value_counts()[:5]\n",
    "print(variation_label)\n",
    "index=variation_label.index\n",
    "print(index)\n",
    "\n",
    "# plotting top 5 variation\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(y=variation_label,x=index);\n",
    "plt.xlabel('Variation')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Top 5 Variation', fontsize=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape of data\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding a len column for analyzing the length of the reviews\n",
    "df['len'] = df['verified_reviews'].map(len)\n",
    "df['len']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# displaying data based on len\n",
    "df.groupby('len').describe().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# displaying the data according to the Ratings\n",
    "df.groupby('rating').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# displaying data based according to the feedback\n",
    "df.groupby('feedback').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization\n",
    "\n",
    "# value counts of rating\n",
    "rating_label = df.rating.value_counts()\n",
    "print(rating_label)\n",
    "index=rating_label.index\n",
    "\n",
    "# barplot\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(x=index, y=rating_label )\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Bar Plot of Ratings', fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram plot of len of reivews\n",
    "\n",
    "len_label = df['len'].value_counts()\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(len_label, bins=100 ,kde=True);\n",
    "plt.xlabel('Length', fontsize=20)\n",
    "plt.ylabel('Count', fontsize=20);\n",
    "plt.title('Distribution of Lenght in Revies', fontsize=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's Check some of the reviews according to thier lengths\n",
    "df[df.len == 1]['verified_reviews'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['len'] == 150]['verified_reviews'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['len'] == 50]['verified_reviews'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['len'] == 25]['verified_reviews'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# box plot \n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.boxplot(x=df['rating'],y= df['len'], palette = 'Blues')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('len')\n",
    "plt.title('Length vs Ratings', fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# violin plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.violinplot(x=df['feedback'],y= df['rating'], palette = 'cool')\n",
    "plt.xlabel('Feedback')\n",
    "plt.ylabel('Rating')\n",
    "plt.title('Feedback vs Ratings', fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# swarmplot\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.swarmplot(x=df['variation'], y=df['len'], palette = 'deep')\n",
    "plt.xlabel('Variation')\n",
    "plt.ylabel('len')\n",
    "plt.xticks(rotation = 75)\n",
    "plt.title(\"Variation vs Length of Ratings\", fontsize=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bivariate analysis \n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.boxenplot(x=df['variation'], y=df['rating'], palette = 'spring')\n",
    "plt.xlabel('Variation')\n",
    "plt.ylabel('Rating')\n",
    "plt.xticks(rotation = 70)\n",
    "plt.title(\"Variation vs Ratings\", fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing of text \n",
    "\n",
    "# CountVectorrizer \n",
    "count_vector = CountVectorizer(stop_words='english') \n",
    "\n",
    "ws = count_vector.fit_transform(df.verified_reviews)\n",
    "s_w = ws.sum(axis=0)\n",
    "w_f = [(w, s_w[0, idx]) for w, idx in count_vector.vocabulary_.items()]\n",
    "w_f = sorted(w_f, key = lambda x: x[1], reverse = True)\n",
    "\n",
    "# creating dataframe\n",
    "freq = pd.DataFrame(w_f, columns=['word', 'freq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# barplot of top 50 frequently occuring words\n",
    "color = plt.cm.ocean(np.linspace(0, 1, 20))\n",
    "freq.head(50).plot(x='word', y='freq', kind='bar', figsize=(15, 6), color = color)\n",
    "plt.xlabel('word')\n",
    "plt.ylabel('length')\n",
    "plt.title('Most Frequently Occuring Words - Top 50',fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# representing words on WordCloud\n",
    "word_cloud = WordCloud(background_color='black', width=1500, height=1400).generate_from_frequencies(dict(w_f))\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.axis('off')\n",
    "plt.imshow(word_cloud)\n",
    "plt.title('Vocabulary from Reviews',fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preproecessing\n",
    "c = []\n",
    "\n",
    "for i in range(0, 3150):\n",
    "    # removing characters except a-z and A-Z\n",
    "    r = re.sub('[^a-zA-Z]', ' ', df['verified_reviews'][i])\n",
    "    # converting every word into lower word\n",
    "    r = r.lower()\n",
    "    # splitting text \n",
    "    r = r.split()\n",
    "    # applying Stemming\n",
    "    ps = PorterStemmer()\n",
    "    # removing stopwords\n",
    "    sw = stopwords.words('english')\n",
    "    sw.remove('not')\n",
    "    r = [ps.stem(word) for word in r if not word in set(sw)]\n",
    "    r = ' '.join(r)\n",
    "    c.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count vectorizer\n",
    "count_vector = CountVectorizer(max_features=2500) \n",
    "\n",
    "# independent and dependent variables\n",
    "X = count_vector.fit_transform(c).toarray()\n",
    "y = df.iloc[:, 4].values\n",
    "\n",
    "# checking shape \n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"shape of X_train: \", X_train.shape)\n",
    "print(\"shape of X_test: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min Max Scaler \n",
    "min_max_sc = MinMaxScaler()\n",
    "\n",
    "X_train = min_max_sc.fit_transform(X_train)\n",
    "X_test = min_max_sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Create and Train the Random Forest Classifier Model\n",
    "\n",
    "Create a Random Forest Classifier model using scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Classifier \n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# fit on data \n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# prediction \n",
    "y_pred = rf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6: Evaluate Model Performance\n",
    "\n",
    "Assess the model's performance using evaluation metrics like Accuracy, Confusion Matrix, Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy Score\n",
    "accuracy=accuracy_score(y_test,y_pred)\n",
    "print('Accuracy Score For The Model=',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report\n",
    "report=classification_report(y_test,y_pred)\n",
    "print('Classification Report',report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix \n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='g')\n",
    "plt.title('Confusion Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 7: HyperParameter Tunning\n",
    "\n",
    "Hyperparameter tuning is the process of finding the best combination of hyperparameters for a machine learning model to optimize its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Tunning\n",
    "\n",
    "p = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [80, 100],\n",
    "    'min_samples_split': [8, 12],\n",
    "    'n_estimators': [100, 300]\n",
    "}\n",
    "\n",
    "# Grid Search CV \n",
    "grid_cv = GridSearchCV(estimator=rf, param_grid=p, cv=10, verbose=0, scoring='accuracy', n_jobs=-1, \n",
    "                       return_train_score=True)\n",
    "grid_cv.fit(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Parameter : {}\".format(grid_cv.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_cv = RandomForestClassifier(bootstrap=True, max_depth=80, min_samples_split=8, n_estimators=300)\n",
    "\n",
    "# fit on data \n",
    "rf_cv.fit(X_train, y_train)\n",
    "\n",
    "# prediction \n",
    "pred = rf_cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy Score\n",
    "accuracy=accuracy_score(y_test,pred)\n",
    "print('Accuracy Score For The Model=',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report\n",
    "report=classification_report(y_test,pred)\n",
    "print('Classification Report',report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix \n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(confusion_matrix(y_test, pred), annot=True, fmt='g')\n",
    "plt.title('Confusion Matrix', fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
